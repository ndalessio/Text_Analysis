cortazar_tibble <- read_csv2("df_cortazar.csv", locale(encoding = "UTF-8"), col_names = TRUE, col_types = NULL)
View(cortazar_tibble)
cortazar_tibble <- read_csv2("df_cortazar.csv",sep=";", locale(encoding = "UTF-8"), col_names = TRUE, col_types = NULL)
cortazar_tibble <- read_csv2("df_cortazar.csv",sep="\t", locale(encoding = "UTF-8"), col_names = TRUE, col_types = NULL)
View(cortazar_tibble)
cortazar_tibble <- read_csv2("df_cortazar.csv", locale(encoding = "UTF-8"), col_names = TRUE, col_types = NULL)
library(tidyverse)
library(tidytext)
cortazar_tibble <- read_csv("df_cortazar.csv", locale(encoding = "UTF-8"), col_names = TRUE, col_types = NULL)
View(cortazar_tibble)
cortazar_tibble <- read_csv("df_cortazar.csv", locale(encoding = "UTF-8"))
View(cortazar_tibble)
cortazar_tibble <- read_csv("df_cortazar.csv", locale(encoding = "UTF-8"), col_names = FALSE, col_types = NULL)
View(cortazar_tibble)
cortazar_tibble <- read_delim("df_cortazar.csv", locale(encoding = "UTF-8"), col_names = TRUE, col_types = NULL)
cortazar_tibble <- read_delim("df_cortazar.csv", locale(encoding = "UTF-8"), col_names = TRUE, col_types = NULL)
cortazar_tibble <- read_tsv("df_cortazar.csv", locale(encoding = "UTF-8"), col_names = TRUE, col_types = NULL)
cortazar_tibble <- read_fwf("df_cortazar.csv", locale(encoding = "UTF-8"), col_names = TRUE, col_types = NULL)
View(cortazar_tibble)
library(readr)
df_cortazar2 <- read_csv("df_cortazar2.csv")
View(df_cortazar2)
View(df_cortazar2)
stories_words <- df_cortazar %>%
select(text) %>%
unnest_tokens(word, text)
head(stories_words)
stories_words <- df_cortazar %>%
select(text) %>%
unnest_tokens(word, text)
library(tidyverse)
library(tidytext)
library(readr)
stories_words <- df_cortazar %>%
select(text) %>%
unnest_tokens(word, text)
df_cortazar <- read_csv("df_cortazar2.csv")
View(df_cortazar2)
View(df_cortazar)
stories_words <- df_cortazar %>%
select(text) %>%
unnest_tokens(word, text)
head(stories_words)
stories_words %>%
count(word, sort = TRUE)
stopwords <- read.csv("https://bitsandbricks.github.io/data/stopwords_es.csv",
stringsAsFactors = FALSE)
df_cortazar_filtered <- df_cortazar %>%
anti_join(stopwords, by = c("word" = "STOPWORD"))
head(stopwords)
df_cortazar_filtered <- stories_words %>%
anti_join(stopwords, by = c("word" = "STOPWORD"))
stories_words_filtered <- stories_words %>%
anti_join(stopwords, by = c("word" = "STOPWORD"))
words_freq <- stories_words_filtered %>% count(word, sort = TRUE)
head(words_freq)
bars_cortazar <- stories_words_filtered %>%
count(word, sort = TRUE) %>%
filter(n > 20) %>%
mutate(word = reorder(word, -n)) %>%
ggplot(aes (word, n)) +
geom_col()
bars_cortazar <- stories_words_filtered %>%
count(word, sort = TRUE) %>%
filter(n > 20) %>%
mutate(word = reorder(word, -n))
library(tidyverse)
bars_cortazar <- stories_words_filtered %>%
count(word, sort = TRUE) %>%
filter(n > 20) %>%
mutate(word = reorder(word, -n))
library(tidyverse)
library(tidytext)
library(readr)
df_cortazar <- read_csv("df_cortazar2.csv")
View(df_cortazar)
# Tokens
stories_words <- df_cortazar %>%
select(text) %>%
unnest_tokens(word, text)
head(stories_words)
# Most frequent words:
stories_words %>%
count(word, sort = TRUE)
# We need to remove stopwords:
stopwords <- read.csv("https://bitsandbricks.github.io/data/stopwords_es.csv",
stringsAsFactors = FALSE)
head(stopwords)
# Deleting stop words from out data set:
stories_words_filtered <- stories_words %>%
anti_join(stopwords, by = c("word" = "STOPWORD"))
# Let's check most frequents words now :D ...
words_freq <- stories_words_filtered %>% count(word, sort = TRUE)
head(words_freq)
# Time to plot!
bars_cortazar <- stories_words_filtered %>%
count(word, sort = TRUE) %>%
filter(n > 20) %>%
mutate(word = reorder(word, -n)) %>%
ggplot(aes (word, n)) +
geom_col()
bars_cortazar
bars_cortazar <- stories_words_filtered %>%
count(word, sort = TRUE) %>%
filter(n > 20) %>%
mutate(word = reorder(word, -n)) %>%
ggplot(aes (word, n)) +
geom_col() +
theme(axis.text.x = element_text(angle = 45))
bars_cortazar
bars_cortazar <- stories_words_filtered %>%
count(word, sort = TRUE) %>%
filter(n > 100) %>%
mutate(word = reorder(word, -n)) %>%
ggplot(aes (word, n)) +
geom_col() +
theme(axis.text.x = element_text(angle = 45))
bars_cortazar
bars_cortazar <- stories_words_filtered %>%
count(word, sort = TRUE) %>%
filter(n > 80) %>%
mutate(word = reorder(word, -n)) %>%
ggplot(aes (word, n)) +
geom_col() +
theme(axis.text.x = element_text(angle = 45))
bars_cortazar
bars_cortazar <- stories_words_filtered %>%
count(word, sort = TRUE) %>%
filter(n > 50) %>%
mutate(word = reorder(word, -n)) %>%
ggplot(aes (word, n)) +
geom_col() +
theme(axis.text.x = element_text(angle = 45))
bars_cortazar
bars_cortazar <- stories_words_filtered %>%
count(word, sort = TRUE) %>%
filter(n > 70) %>%
mutate(word = reorder(word, -n)) %>%
ggplot(aes (word, n)) +
geom_col() +
theme(axis.text.x = element_text(angle = 45))
bars_cortazar
bars_cortazar <- stories_words_filtered %>%
count(word, sort = TRUE) %>%
filter(n > 70) %>%
mutate(word = reorder(word, -n)) %>%
ggplot(aes (word, n)) +
geom_col(fill = "red") +
theme(axis.text.x = element_text(angle = 45))
bars_cortazar
bars_cortazar <- stories_words_filtered %>%
count(word, sort = TRUE) %>%
filter(n > 70) %>%
mutate(word = reorder(word, -n)) %>%
ggplot(aes (word, n)) +
geom_col(fill = "red") +
theme(axis.text.x = element_text(angle = 45)) +
ylab("Frecuencia de uso") +
xlab("Palabra") +
ggtitle("Palabras más utilizadas en 37 cuentos scrapeados de Cortázar") +
subtitle("Fuente del corpus: 'Ciudad Seva'")
bars_cortazar
bars_cortazar <- stories_words_filtered %>%
count(word, sort = TRUE) %>%
filter(n > 70) %>%
mutate(word = reorder(word, -n)) %>%
ggplot(aes (word, n)) +
geom_col(fill = "red") +
theme(axis.text.x = element_text(angle = 45)) +
ylab("Frecuencia de uso") +
xlab("Palabra") +
ggtitle(label = "Palabras más utilizadas en 37 cuentos scrapeados de Julio Cortázar",
subtitle = "Fuente del corpus: 'Ciudad Seva'")
bars_cortazar
bars_cortazar <- stories_words_filtered %>%
count(word, sort = TRUE) %>%
filter(n > 70) %>%
mutate(word = reorder(word, -n)) %>%
ggplot(aes (word, n)) +
geom_col(fill = "red") +
theme(axis.text.x = element_text(angle = 45)) +
ylab("Frecuencia de uso") +
xlab("Palabra") +
ggtitle(label = "Palabras más utilizadas en 37 cuentos scrapeados de Julio Cortázar",
subtitle = 'Fuente del corpus: "Ciudad Seva"')
bars_cortazar
library(wordcloud2)
wordcloud2(data = words_freq)
wordcloud2(data = words_freq)
head(words_freq)
stories_words %>%
count(word, sort = TRUE)
head(stories_words)
bigrams <- df_cortazar %>%
separate(bigram, c("word1", "word2"), sep = " ")
bigrams <- df_cortazar %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
# Bigrams
bigrams <- df_cortazar %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
# We separate bigrams in two, so we can delete stopwords
bigrams_separate <- bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
# Filtering stopwords
bigrams_filtered <- bigrams_separate %>%
filter(!word1 %in% stopwords$STOPWORDS) %>%
filter(!word2 %in% stopwords$STOPWORDS)
# Joining again:
bigrams_joined <- bigrams_filtered %>%
unite(bigram, word1, word2, sep = " ") %>%
count(bigram, sort = TRUE) %>%
filter(bigram!="NA NA")
# Ploting :) :)
wordcloud2(bigrams_joined)
library(tidyverse)
library(tidytext)
library(readr)
df_cortazar <- read_csv("df_cortazar2.csv")
View(df_cortazar)
# Tokens
stories_words <- df_cortazar %>%
select(text) %>%
unnest_tokens(word, text)
head(stories_words)
# Most frequent words:
stories_words %>%
count(word, sort = TRUE)
# We need to remove stopwords:
stopwords <- read.csv("https://bitsandbricks.github.io/data/stopwords_es.csv",
stringsAsFactors = FALSE)
head(stopwords)
# Deleting stop words from out data set:
stories_words_filtered <- stories_words %>%
anti_join(stopwords, by = c("word" = "STOPWORD"))
# Let's check most frequents words now :D ...
words_freq <- stories_words_filtered %>% count(word, sort = TRUE)
head(words_freq)
# Time to plot!
# Bar plot:
bars_cortazar <- stories_words_filtered %>%
count(word, sort = TRUE) %>%
filter(n > 70) %>%
mutate(word = reorder(word, -n)) %>%
ggplot(aes (word, n)) +
geom_col(fill = "red") +
theme(axis.text.x = element_text(angle = 45)) +
ylab("Frecuencia de uso") +
xlab("Palabra") +
ggtitle(label = "Palabras más utilizadas en 37 cuentos scrapeados de Julio Cortázar",
subtitle = 'Fuente del corpus: "Ciudad Seva"')
bars_cortazar
# Word cloud:
library(wordcloud2)
wordcloud2(data = words_freq)
# Bigrams
bigrams <- df_cortazar %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
# We separate bigrams in two, so we can delete stopwords
bigrams_separate <- bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
# Filtering stopwords
bigrams_filtered <- bigrams_separate %>%
filter(!word1 %in% stopwords$STOPWORDS) %>%
filter(!word2 %in% stopwords$STOPWORDS)
# Joining again:
bigrams_joined <- bigrams_filtered %>%
unite(bigram, word1, word2, sep = " ") %>%
count(bigram, sort = TRUE) %>%
filter(bigram!="NA NA")
# Ploting :) :)
wordcloud2(bigrams_joined)
# Ploting :) :)
wordcloud2(bigrams_joined)
# Bigrams
bigrams <- df_cortazar %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
# We separate bigrams in two, so we can delete stopwords
bigrams_separate <- bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
# Filtering stopwords
bigrams_filtered <- bigrams_separate %>%
filter(!word1 %in% stopwords$STOPWORDS) %>%
filter(!word2 %in% stopwords$STOPWORDS)
# Joining again:
bigrams_joined <- bigrams_filtered %>%
unite(bigram, word1, word2, sep = " ") %>%
count(bigram, sort = TRUE) %>%
filter(bigram!="NA NA")
# Ploting :) :)
wordcloud2(bigrams_joined)
stopwords <- read.csv("https://bitsandbricks.github.io/data/stopwords_es.csv",
stringsAsFactors = FALSE)
# Filtering stopwords
bigrams_filtered <- bigrams_separate %>%
filter(!word1 %in% stopwords$STOPWORDS) %>%
filter(!word2 %in% stopwords$STOPWORDS)
# Joining again:
bigrams_joined <- bigrams_filtered %>%
unite(bigram, word1, word2, sep = " ") %>%
count(bigram, sort = TRUE) %>%
filter(bigram!="NA NA")
# Ploting :) :)
wordcloud2(bigrams_joined)
View(stopwords)
# We separate bigrams in two, so we can delete stopwords
bigrams_separated <- bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
# Filtering stopwords
bigrams_filtered <- bigrams_separated %>%
filter(!word1 %in% stopwords$STOPWORDS) %>%
filter(!word2 %in% stopwords$STOPWORDS)
bigrams_filtered %>%
count(word1, sort = TRUE)
library(tidyverse)
library(tidytext)
library(readr)
df_cortazar <- read_csv("df_cortazar2.csv")
View(df_cortazar)
# Tokens
stories_words <- df_cortazar %>%
select(text) %>%
unnest_tokens(word, text)
head(stories_words)
# Most frequent words:
stories_words %>%
count(word, sort = TRUE)
# We need to remove stopwords:
stopwords <- read.csv("https://bitsandbricks.github.io/data/stopwords_es.csv",
stringsAsFactors = FALSE)
head(stopwords)
# Deleting stop words from out data set:
stories_words_filtered <- stories_words %>%
anti_join(stopwords, by = c("word" = "STOPWORD"))
# Let's check most frequents words now :D ...
words_freq <- stories_words_filtered %>% count(word, sort = TRUE)
head(words_freq)
# Time to plot!
# Bar plot:
bars_cortazar <- stories_words_filtered %>%
count(word, sort = TRUE) %>%
filter(n > 70) %>%
mutate(word = reorder(word, -n)) %>%
ggplot(aes (word, n)) +
geom_col(fill = "red") +
theme(axis.text.x = element_text(angle = 45)) +
ylab("Frecuencia de uso") +
xlab("Palabra") +
ggtitle(label = "Palabras más utilizadas en 37 cuentos scrapeados de Julio Cortázar",
subtitle = 'Fuente del corpus: "Ciudad Seva"')
bars_cortazar
# Ploting word cloud:
library(wordcloud2)
wordcloud2(data = words_freq)
# Bigrams
bigrams <- df_cortazar %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
# We separate bigrams in two, so we can delete stopwords
bigrams_separated <- bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
# Filtering stopwords
bigrams_filtered <- bigrams_separated %>%
filter(!word1 %in% stopwords$STOPWORDS) %>%
filter(!word2 %in% stopwords$STOPWORDS)
bigrams_filtered %>%
count(word1, sort = TRUE)
# Joining again:
bigrams_joined <- bigrams_filtered %>%
unite(bigram, word1, word2, sep = " ") %>%
count(bigram, sort = TRUE) %>%
filter(bigram != "NA NA")
# Ploting :) :)
wordcloud2(bigrams_joined)
bigrams_joined %>%
count(bigram, sort = TRUE)
# Ploting :) :)
wordcloud2(bigrams_joined)
bigrams_joined %>%
count(bigram)
bigrams_joined %>%
count(bigram) %>%
arrange(bigram)
# Joining again:
bigrams_joined <- bigrams_filtered %>%
unite(bigram, word1, word2, sep = " ") %>%
count(bigram, sort = TRUE) %>%
filter(bigram != "NA NA")
View(bigrams_joined)
stopwords$STOPWORD
stopwords <- read.csv("https://bitsandbricks.github.io/data/stopwords_es.csv",
stringsAsFactors = FALSE, encoding = "utf-8")
View(stopwords)
stopwords <- read.csv("https://bitsandbricks.github.io/data/stopwords_es.csv",
stringsAsFactors = FALSE, fileEncoding="utf-8")
library(tidyverse)
library(tidytext)
library(readr)
df_cortazar <- read_csv("df_cortazar2.csv")
View(df_cortazar)
# Tokens
stories_words <- df_cortazar %>%
select(text) %>%
unnest_tokens(word, text)
head(stories_words)
# Most frequent words:
stories_words %>%
count(word, sort = TRUE)
# We need to remove stopwords:
stopwords <- read.csv("https://bitsandbricks.github.io/data/stopwords_es.csv",
stringsAsFactors = FALSE, fileEncoding="utf-8")
head(stopwords)
# Deleting stop words from out data set:
stories_words_filtered <- stories_words %>%
anti_join(stopwords, by = c("word" = "STOPWORD"))
# Let's check most frequents words now :D ...
words_freq <- stories_words_filtered %>% count(word, sort = TRUE)
head(words_freq)
# Time to plot!
# Bar plot:
bars_cortazar <- stories_words_filtered %>%
count(word, sort = TRUE) %>%
filter(n > 70) %>%
mutate(word = reorder(word, -n)) %>%
ggplot(aes (word, n)) +
geom_col(fill = "red") +
theme(axis.text.x = element_text(angle = 45)) +
ylab("Frecuencia de uso") +
xlab("Palabra") +
ggtitle(label = "Palabras más utilizadas en 37 cuentos scrapeados de Julio Cortázar",
subtitle = 'Fuente del corpus: "Ciudad Seva"')
bars_cortazar
# Ploting word cloud:
library(wordcloud2)
wordcloud2(data = words_freq)
# Bigrams
bigrams <- df_cortazar %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
# We separate bigrams in two, so we can delete stopwords
bigrams_separated <- bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
# Filtering stopwords
bigrams_filtered <- bigrams_separated %>%
filter(!word1 %in% stopwords$STOPWORDS) %>%
filter(!word2 %in% stopwords$STOPWORDS)
bigrams_filtered %>%
count(word1, sort = TRUE)
# Joining again:
bigrams_joined <- bigrams_filtered %>%
unite(bigram, word1, word2, sep = " ") %>%
count(bigram, sort = TRUE) %>%
filter(bigram != "NA NA")
# Ploting :) :)
wordcloud2(bigrams_joined)
# Filtering stopwords
bigrams_filtered <- bigrams_separated %>%
anti_join(stopwords, by = c("word1" = "STOPWORD")) %>%
anti_join(stopwords, by = c("word2" = "STOPWORD"))
bigrams_filtered %>%
count(word1, sort = TRUE)
bigrams_filtered
# Joining again:
bigrams_joined <- bigrams_filtered %>%
unite(bigram, word1, word2, sep = " ") %>%
count(bigram, sort = TRUE) %>%
filter(bigram != "NA NA")
# Ploting :) :)
wordcloud2(bigrams_joined)
wordcloud2(data = words_freq)
# Ploting :) :)
wordcloud2(bigrams_joined)
wordcloud2(data = words_freq)
# Ploting :) :)
wordcloud2(bigrams_joined)
# Ploting :) :)
wordcloud2(bigrams_joined)
# Ploting :) :)
wordcloud2(bigrams_joined)
bars_cortazar <- stories_words_filtered %>%
count(word, sort = TRUE) %>%
filter(n > 80) %>%
mutate(word = reorder(word, -n)) %>%
ggplot(aes (word, n)) +
geom_col(fill = "mediumpurple") +
theme(axis.text.x = element_text(angle = 45)) +
ylab("Frecuencia de uso") +
xlab("Palabra") +
ggtitle(label = "Palabras más utilizadas en 37 cuentos scrapeados de Julio Cortázar",
subtitle = 'Fuente del corpus: "Ciudad Seva"')
bars_cortazar
bars_cortazar <- stories_words_filtered %>%
count(word, sort = TRUE) %>%
filter(n > 100) %>%
mutate(word = reorder(word, -n)) %>%
ggplot(aes (word, n)) +
geom_col(fill = "mediumpurple") +
theme(axis.text.x = element_text(angle = 45)) +
ylab("Frecuencia de uso") +
xlab("Palabra") +
ggtitle(label = "Palabras más utilizadas en 37 cuentos scrapeados de Julio Cortázar",
subtitle = 'Fuente del corpus: "Ciudad Seva"')
bars_cortazar
bars_cortazar <- stories_words_filtered %>%
count(word, sort = TRUE) %>%
filter(n > 100) %>%
mutate(word = reorder(word, -n)) %>%
ggplot(aes (word, n)) +
geom_col(fill = "mediumpurple") +
theme(axis.text.x = element_text(angle = 45)) +
ylab("Frecuencia de uso") +
xlab("Palabra") +
ggtitle(label = "Palabras más utilizadas en cuentos scrapeados de Julio Cortázar",
subtitle = 'Fuente del corpus: "Ciudad Seva"')
bars_cortazar
